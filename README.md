# AIN-212-214
HW1: Initial Data Exploration & Visualization
In this project, I loaded a small dataset, cleaned missing and inconsistent values, and performed basic exploratory analysis. Using Python libraries such as Pandas and MatPlotLib, I visualized key features to quickly uncover trends and patterns. Also I create tables using sqlite and applied various queries.

HW2: SQL-Driven Data Analysis
Here, I focused on writing efficient SQL queries to join multiple tables, group and filter data, and derive structured insights. This allowed me to merge SQL outputs with Python-based workflows for a more comprehensive analysis.

HW3: Regression Models
For HW3, I built linear and multiple regression models using scikit-learn. Through metric evaluations (MSE, MAE, R²), I identified the most effective model configurations and explored basic hyperparameter tuning strategies.

HW4: Classification & Model Comparison
This assignment involved applying classification algorithms like Logistic Regression and Decision Trees on a mixed-type dataset. Model performance was compared using metrics such as precision, recall, F1-score, and ROC/AUC, highlighting overfitting and underfitting solutions.

HW5: Advanced Data Analysis & Visualization
In HW5, I used larger, high-dimensional datasets and techniques like PCA to reduce complexity. Interactive visualizations with Plotly revealed hidden data structures and enabled a more intuitive understanding of complex relationships.

AIN212Project: Flood Detection & Comprehensive Pipeline
For this end-to-end project, I used a flood dataset to determine whether flooding occurred or not. After extensive data cleaning and preparation, I applied multiple classification algorithms (e.g., Logistic Regression, Decision Trees, and SVM) to compare accuracy scores and identify the best-performing model. PCA was integrated to reduce dimensionality and reveal clustering patterns, while additional unsupervised methods helped explore potential groupings within the data. Throughout the process, I prioritized thorough data analysis—detecting and handling outliers, normalizing features, and carefully splitting the dataset to ensure robust model training. This comprehensive approach not only provided insights into which algorithm best classified flood presence but also demonstrated the importance of feature selection, careful preprocessing, and methodical evaluation.
